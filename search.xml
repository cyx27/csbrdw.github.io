<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Log4J</title>
      <link href="/2023/07/05/Log4J/"/>
      <url>/2023/07/05/Log4J/</url>
      
        <content type="html"><![CDATA[<p>Log4j由三个重要的组件构成：日志信息的优先级，日志信息的输出目的地，日志信息的输出格式。日志信息的优先级从高到低有ERROR、WARN、 INFO、DEBUG，分别用来指定这条日志信息的重要程度；日志信息的输出目的地指定了日志将打印到控制台还是文件中；而输出格式则控制了日志信息的显示内容</p><h1 id="定义配置文件"><a href="#定义配置文件" class="headerlink" title="定义配置文件"></a>定义配置文件</h1><p>其实您也可以完全不使用配置文件，而是在代码中配置Log4j环境。但是，使用配置文件将使您的应用程序更加灵活。Log4j支持两种配置文件格式，一种是XML格式的文件，一种是Java特性文件（键&#x3D;值）。下面我们介绍使用Java特性文件做为配置文件的方法：</p><ol><li>配置根Logger，其语法为：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger = [ level ] , appenderName, appenderName, …</span><br></pre></td></tr></table></figure><p>其中，level 是日志记录的优先级，分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者您定义的级别。Log4j建议只使用四个级别，优 先级从高到低分别是ERROR、WARN、INFO、DEBUG。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。比如在这里定 义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来。 appenderName就是指把日志信息输出到哪个地方。您可以同时指定多个输出目的地，例如上述例子我们制定了stdout、D和E这三个地方。</p><ol><li>配置文件的输出目的地Appender，一般，配置代码的格式如下</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">log4j.appender.appenderName = fully.qualified.name.of.appender.class  </span><br><span class="line">log4j.appender.appenderName.option1 = value1  </span><br><span class="line">…  </span><br><span class="line">log4j.appender.appenderName.option = valueN</span><br></pre></td></tr></table></figure><p>其中，Log4j提供的appender有以下几种：</p><ul><li>org.apache.log4j.ConsoleAppender（控制台），</li><li>org.apache.log4j.FileAppender（文件），</li><li>org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），</li><li>org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件），</li><li>org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）</li></ul><ol><li>配置日志信息的格式（布局），其语法为：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">log4j.appender.appenderName.layout = fully.qualified.name.of.layout.class  </span><br><span class="line">log4j.appender.appenderName.layout.option1 = value1  </span><br><span class="line">…  </span><br><span class="line">log4j.appender.appenderName.layout.option = valueN</span><br></pre></td></tr></table></figure><p>其中，Log4j提供的layout有以下几种：</p><ul><li>org.apache.log4j.HTMLLayout（以HTML表格形式布局），</li><li>org.apache.log4j.PatternLayout（可以灵活地指定布局模式），</li><li>org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），</li><li>org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）</li></ul><p>Log4J采用类似C语言中的printf函数的打印格式格式化日志信息，打印参数如下：</p><ul><li>%m 输出代码中指定的消息</li><li>%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL</li><li>%r 输出自应用启动到输出该log信息耗费的毫秒数</li><li>%c 输出所属的类目，通常就是所在类的全名</li><li>%t 输出产生该日志事件的线程名</li><li>%n 输出一个回车换行符，Windows平台为“rn”，Unix平台为“n”</li><li>%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss,SSS}，输出类似：2002年10月18日 22：10：28，921</li><li>%l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java:10)</li></ul><h1 id="在代码中使用Log4j"><a href="#在代码中使用Log4j" class="headerlink" title="在代码中使用Log4j"></a>在代码中使用Log4j</h1><ol><li>获取记录器使用Log4j，第一步就是获取日志记录器，这个记录器将负责控制日志信息。其语法为：<code>public static Logger getLogger( String name)</code>；通过指定的名字获得记录器，如果必要的话，则为这个名字创建一个新的记录器。Name一般取本类的名字，比如：<code>static Logger logger = Logger.getLogger ( ServerWithLog4j.class.getName () )</code>。</li><li>读取配置文件当获得了日志记录器之后，第二步将配置Log4j环境，其语法为：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BasicConfigurator.configure ()： 自动快速地使用缺省Log4j环境。  </span><br><span class="line">PropertyConfigurator.configure ( String configFilename) ：读取使用Java的特性文件编写的配置文件。  </span><br><span class="line">DOMConfigurator.configure ( String filename ) ：读取XML形式的配置文件。</span><br></pre></td></tr></table></figure><ol><li>插入记录信息（格式化日志信息）当上两个必要步骤执行完毕，您就可以轻松地使用不同优先级别的日志记录语句插入到您想记录日志的任何地方，其语法如下：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Logger.debug(Object message);  </span><br><span class="line">Logger.info(Object message);  </span><br><span class="line">Logger.warn(Object message);  </span><br><span class="line">Logger.error(Object message);</span><br></pre></td></tr></table></figure><h1 id="日志级别"><a href="#日志级别" class="headerlink" title="日志级别"></a>日志级别</h1><p>每个Logger都被了一个日志级别（log level），用来控制日志信息的输出。日志级别从高到低分为： A：off 最高等级，用于关闭所有日志记录。 B：fatal 指出每个严重的错误事件将会导致应用程序的退出。 C：error 指出虽然发生错误事件，但仍然不影响系统的继续运行。 D：warm 表明会出现潜在的错误情形。 E：info 一般和在粗粒度级别上，强调应用程序的运行全程。 F：debug 一般用于细粒度级别上，对调试应用程序非常有帮助。 G：all 最低等级，用于打开所有日志记录。</p><p>上面这些级别是定义在org.apache.log4j.Level类中。Log4j只建议使用4个级别，优先级从高到低分别是error,warn,info和debug。通过使用日志级别，可以控制应用程序中相应级别日志信息的输出。例如，如果使用b了info级别，则应用程序中所有低于info级别的日志信息(如debug)将不会被打印出来。</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>commit 规范</title>
      <link href="/2023/07/05/commit-%E8%A7%84%E8%8C%83/"/>
      <url>/2023/07/05/commit-%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<h1 id="commit-message格式"><a href="#commit-message格式" class="headerlink" title="commit message格式"></a>commit message格式</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;</span><br></pre></td></tr></table></figure><p><strong>type(必须)</strong></p><p>用于说明git commit的类别，只允许使用下面的标识。</p><p>feat：新功能（feature）。</p><p>fix&#x2F;to：修复bug，可以是QA发现的BUG，也可以是研发自己发现的BUG。</p><ul><li>fix：产生diff并自动修复此问题。适合于一次提交直接修复问题</li><li>to：只产生diff不自动修复此问题。适合于多次提交。最终修复问题提交时使用fix</li></ul><p>docs：文档（documentation）。</p><p>style：格式（不影响代码运行的变动）。</p><p>refactor：重构（即不是新增功能，也不是修改bug的代码变动）。</p><p>perf：优化相关，比如提升性能、体验。</p><p>test：增加测试。</p><p>chore：构建过程或辅助工具的变动。</p><p>revert：回滚到上一个版本。</p><p>merge：代码合并。</p><p>sync：同步主线或分支的Bug。</p><p><strong>scope(可选)</strong></p><p>scope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。</p><p>例如在Angular，可以是location，browser，compile，compile，rootScope， ngHref，ngClick，ngView等。如果你的修改影响了不止一个scope，你可以使用*代替。</p><p><strong>subject(必须)</strong></p><p>subject是commit目的的简短描述，不超过50个字符。</p><p>建议使用中文（感觉中国人用中文描述问题能更清楚一些）。</p><ul><li>结尾不加句号或其他标点符号。</li><li>根据以上规范git commit message将是如下的格式：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fix(DAO):用户查询缺少username属性 </span><br><span class="line">feat(Controller):用户查询接口开发</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集合</title>
      <link href="/2023/07/03/%E9%9B%86%E5%90%88/"/>
      <url>/2023/07/03/%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><p><strong>参数说明：</strong></p><ul><li>key - 键</li><li>remappingFunction - 重新映射函数，用于重新计算值</li></ul><h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>如果 key 对应的 value 不存在，则使用获取 remappingFunction 重新计算后的值，并保存为该 key 的 value，否则返回 value。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">default</span> V <span class="title function_">computeIfAbsent</span><span class="params">(K key,</span></span><br><span class="line"><span class="params">        Function&lt;? <span class="built_in">super</span> K, ? extends V&gt; mappingFunction)</span> &#123;</span><br><span class="line">    Objects.requireNonNull(mappingFunction);</span><br><span class="line">    V v;</span><br><span class="line">    <span class="keyword">if</span> ((v = get(key)) == <span class="literal">null</span>) &#123;</span><br><span class="line">        V newValue;</span><br><span class="line">        <span class="keyword">if</span> ((newValue = mappingFunction.apply(key)) != <span class="literal">null</span>) &#123;</span><br><span class="line">            put(key, newValue);</span><br><span class="line">            <span class="keyword">return</span> newValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> v;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可使用 lambda 匿名函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 创建一个 HashMap</span></span><br><span class="line">        HashMap&lt;String, Integer&gt; prices = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 往HashMap中添加映射项</span></span><br><span class="line">        prices.put(<span class="string">&quot;Shoes&quot;</span>, <span class="number">200</span>);</span><br><span class="line">        prices.put(<span class="string">&quot;Bag&quot;</span>, <span class="number">300</span>);</span><br><span class="line">        prices.put(<span class="string">&quot;Pant&quot;</span>, <span class="number">150</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;HashMap: &quot;</span> + prices);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算 Shirt 的值</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">shirtPrice</span> <span class="operator">=</span> prices.computeIfAbsent(<span class="string">&quot;Shirt&quot;</span>, key -&gt; <span class="number">280</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;Price of Shirt: &quot;</span> + shirtPrice);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出更新后的HashMap</span></span><br><span class="line">        System.out.println(<span class="string">&quot;Updated HashMap: &quot;</span> + prices);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行以上程序输出结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HashMap: &#123;Pant=150, Bag=300, Shoes=200&#125;</span><br><span class="line">Price of Shirt: 280</span><br><span class="line">Updated HashMap: &#123;Pant=150, Shirt=280, Bag=300, Shoes=200&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git</title>
      <link href="/2023/07/03/git/"/>
      <url>/2023/07/03/git/</url>
      
        <content type="html"><![CDATA[<h2 id="1、简单了解git"><a href="#1、简单了解git" class="headerlink" title="1、简单了解git"></a>1、简单了解git</h2><h3 id="1-1、分布式版本控制系统（Distributed-Version-Control-System）"><a href="#1-1、分布式版本控制系统（Distributed-Version-Control-System）" class="headerlink" title="1.1、分布式版本控制系统（Distributed Version Control System）"></a>1.1、分布式版本控制系统（Distributed Version Control System）</h3><p>客户端从远程仓库中不只是提取最新版本的文件快照，而是把代码仓库完整的镜像下来，包括历史记录。如此相当于所有的客户端都是仓库的分布式节点。任何一个协同工作的机器发生故障，都可以用其他的镜像恢复，包括远程仓库。</p><h3 id="1-2、git-文件命名规则"><a href="#1-2、git-文件命名规则" class="headerlink" title="1.2、git 文件命名规则"></a>1.2、git 文件命名规则</h3><p>git 的文件名是由文件内容和目录结构通过 SHA-1 散列（哈希）计算出来的。所以git 数据库中保存的信息实际上都是以文件内容的哈希值来索引。如果文件内容或者目录结构变化，hash 值肯定会发生变化，因此可以使用此值来保证git 文件的完整性。（这就是为什么 rebase 的时候，commitId 会发生变化的原因）</p><h3 id="1-3、初始化本地git-仓库"><a href="#1-3、初始化本地git-仓库" class="headerlink" title="1.3、初始化本地git 仓库"></a>1.3、初始化本地git 仓库</h3><ul><li>进入本地项目目录下，执行init命令，命令执行后，在目录下会生成 .git 子目录<code>cd /code/myCode``git init</code></li><li>将文件加入到本地仓库<code>git add *.java``git commit -m &quot;init data&quot;</code></li></ul><h3 id="1-4、远程仓库及克隆"><a href="#1-4、远程仓库及克隆" class="headerlink" title="1.4、远程仓库及克隆"></a>1.4、远程仓库及克隆</h3><ul><li>克隆<code>git clone &lt;url&gt;</code> 此命令远程仓库下的每一个文件，每一个版本都将被拉取下来。如果远程仓库磁盘坏了，可以随时用本地仓库恢复远程仓库数据例：<code>git clone https://github.com/libgit2/libgit2</code></li><li>远程仓库简称一个git 本地仓库可以绑定多个远程仓库，每个远程仓库对应一个简称，默认简称 origin查看仓库简称：<code>git remote</code></li></ul><p><img src="https://pic4.zhimg.com/80/v2-93f6365c47a1a7510c9a3861e09b9db3_720w.webp" alt="img"></p><ul><li>新增一个远程仓库<code>git remote add &lt;name&gt; &lt;url&gt;</code></li><li>查看当前已绑定的远程仓库<code>git remote -v</code>当前绑定了两个远程仓库，分别简称 origin，<a href="https://link.zhihu.com/?target=http://coding.net">http://coding.net</a></li></ul><p><img src="https://pic4.zhimg.com/80/v2-d1523ba9ef2e0b33be72838b3fbac64b_720w.webp" alt="img"></p><ul><li>指定两个远程仓库，本地仓库状态就有可能出现如下情况不同远程仓库，master 分支处于不同的commit 处</li></ul><p><img src="https://pic3.zhimg.com/80/v2-945bb649196ecd6b701e412cd0098f42_720w.webp" alt="img"></p><ul><li>此时进行 push 和 pull 操作需要指定目标仓库 (简称使用)<code>git push/pull &lt;remote&gt; master</code>例：<code>git push origin master``git pull coding.net master</code>首次向新仓库推送master 分支：<code>git push -u &lt;remote&gt; master</code></li><li>远程仓库信息查看命令：<code>git remote show &lt;remote&gt;</code>例：<code>git remote show origin</code></li></ul><p><img src="https://pic3.zhimg.com/80/v2-c8125d0a2a303b086d51e2537840fcfe_720w.webp" alt="img"></p><ul><li>远程仓库简称重命名例：将远程仓库简称 origin 重命名为 newName<code>git remote rename origin newName</code></li></ul><h3 id="1-5、-x2F-git-目录说明"><a href="#1-5、-x2F-git-目录说明" class="headerlink" title="1.5、.&#x2F;git 目录说明"></a>1.5、.&#x2F;git 目录说明</h3><p>在一个新目录下执行 git init 命令，Git 会创建一个 .git 目录。该目录包含了几乎所有git 存储和操作的东西，如果想要备份或复制一个版本库，只需要吧这个目录拷贝到另一处即可。.&#x2F;git 目录结构如下</p><p><img src="https://pic4.zhimg.com/80/v2-705d6aa8776a734436a9b77b9fba1813_720w.webp" alt="img"></p><ul><li><strong>config</strong>：包含项目特有的配置选项（分支等）</li><li><strong>HEAD</strong>：指向当前被检出的分支</li><li><strong>COMMIT_EDITMSG</strong>：上次提交或准备提交的 commit msg 记录</li><li><strong>index</strong>：保存暂存区信息</li><li><strong>hooks目录</strong>：客户端或服务端的钩子脚本。</li><li><strong>info目录</strong>：全局性排除，那些需要排除但是不希望记录在 .gitignore 文件中的排除文件记录在这个目录下的exclude 文件中</li><li><strong>object目录</strong>：存储所有的数据内容</li><li><strong>refs目录</strong>：存储指向数据（分支、远程仓库和标签）的提交对象指针注意：git 的 gc 会将 git refs 中的文件整合保存到 .git&#x2F;packed-fefs 中，保证git 执行效率分支快速检出。如果更新了引用，git 不会更新 packed-fefs 文件，只会在 .&#x2F;git&#x2F;refs&#x2F;heads 下加一条数据。所以引用的寻找都是先找 .&#x2F;git&#x2F;refs&#x2F;heads 下的数据，当 .&#x2F;git&#x2F;refs&#x2F;heads 下找不到数据，再去 .git&#x2F;packed-fefs 中找</li><li><strong>packed-refs</strong>：记录分支当前在哪个 commit 节点上</li></ul><h2 id="2、git-对象"><a href="#2、git-对象" class="headerlink" title="2、git 对象"></a>2、git 对象</h2><p>git 存储的所有数据内容保存在 .&#x2F;git&#x2F;object 下，该目录下保存的文件在 git 中对应一个一个的对象，可使用 ：<code>git cat-file -t &lt;SHA-1&gt;</code> 命令查看文件对应的对象类型。</p><h3 id="2-1、-x2F-git-x2F-object-目录说明"><a href="#2-1、-x2F-git-x2F-object-目录说明" class="headerlink" title="2.1、.&#x2F;git&#x2F;object 目录说明"></a>2.1、.&#x2F;git&#x2F;object 目录说明</h3><ul><li>查看object 目录下文件信息<code>git cat-file</code> 命令可以解析 object 目录下文件的内容</li><li><ul><li>查看文件内容：<code>git cat-file -p &lt;SHA-1&gt;``&lt;SHA-1&gt;</code> ：为 objects 下目录名称和文件名称，文件名称部分前缀也可以，只要不会有文件重复</li></ul></li></ul><p><img src="https://pic2.zhimg.com/80/v2-2aad618f1a4dee2f4a7e9d3c36a2df79_720w.webp" alt="img"></p><ul><li><ul><li>查看文件类型：<code>git cat-file -t &lt;SHA-1&gt;</code></li></ul></li></ul><p><img src="https://pic4.zhimg.com/80/v2-2b05dd96449bd7c06f58270154f2bacf_720w.webp" alt="img"></p><ul><li>object 下目录及文件命名规则通过文件内容外加一个头部信息一起做 <code>SHA-1</code> 哈希值，以此值得前两个字符用于命名子目录，余下得 38 个字符用作文件名</li></ul><h3 id="2-2、blob-对象"><a href="#2-2、blob-对象" class="headerlink" title="2.2、blob 对象"></a>2.2、blob 对象</h3><p>一个blob 对象对应一个文件快照，保存文件具体内容</p><ul><li>例：查看blob 对象 0b3f 的文件内容</li></ul><p><img src="https://pic1.zhimg.com/80/v2-467f4be59744897664dcba1dcd828578_720w.webp" alt="img"></p><h3 id="2-3、tree-对象"><a href="#2-3、tree-对象" class="headerlink" title="2.3、tree 对象"></a>2.3、tree 对象</h3><p>树对象的每条记录含有一个指向数据对象或者子树对象的 SHA-1 指针</p><ul><li>例：找到 master 分支上最新的提交所指的树对象：<code>git cat-file -p master^&#123;tree&#125;</code>以下树对象指向 5 个 blob 文件，指向 5 个父级树，通过对父级树的递归查找 blob 对象，可以将该树下包含的整个项目文件都找到</li></ul><p><img src="https://pic2.zhimg.com/80/v2-5aa5a0260d3655764b102948f6e9686d_720w.webp" alt="img"></p><ul><li>例：7c19 为树对象，查看该对象内容</li></ul><p><img src="https://pic1.zhimg.com/80/v2-93d25f79e017e7d385315128ea55e4c8_720w.webp" alt="img"></p><h3 id="2-4、commit-对象"><a href="#2-4、commit-对象" class="headerlink" title="2.4、commit 对象"></a>2.4、commit 对象</h3><p>git 的工作实质是将被改写的文件保存为数据对象(blob)，更新暂存区，记录树对象tree，最后创建一个指向顶层树对象和父提交对象的提交对象(commit)</p><ul><li>例：1e38 为commit 对象，查看该对象内容</li></ul><p><img src="https://pic3.zhimg.com/80/v2-2b4cd81e1c0edce340e706ebb690edd6_720w.webp" alt="img"></p><h3 id="2-5、tag-对象"><a href="#2-5、tag-对象" class="headerlink" title="2.5、tag 对象"></a>2.5、tag 对象</h3><p>打 tag 操作生成的对象类型</p><ul><li>例</li></ul><p><img src="https://pic4.zhimg.com/80/v2-8095e983baf014b664f4d21867add327_720w.webp" alt="img"></p><h3 id="2-6、commit、blob、tree-的关系图解"><a href="#2-6、commit、blob、tree-的关系图解" class="headerlink" title="2.6、commit、blob、tree 的关系图解"></a>2.6、commit、blob、tree 的关系图解</h3><ul><li>假设首次提交包含三个改变的文件，提交后产生的文件结构如下commit 指向 tree 并记录提交者和提交时间。tree 指向三个 blob 文件，记录文件快照位置</li></ul><p><img src="https://pic1.zhimg.com/80/v2-f2a45bcec92eda04da30cb30471c4364_720w.webp" alt="img"></p><ul><li>假设对文件进行修改后再次提交commit 内容中将多一个 parent 信息，指向上个 commit 节点。</li></ul><p><img src="https://pic3.zhimg.com/80/v2-b0e12efc557cabbd158dbfcff94992a2_720w.webp" alt="img"></p><h2 id="3、git-的三个分区"><a href="#3、git-的三个分区" class="headerlink" title="3、git 的三个分区"></a>3、git 的三个分区</h2><h3 id="3-1-三个分区说明"><a href="#3-1-三个分区说明" class="headerlink" title="3.1 三个分区说明"></a>3.1 三个分区说明</h3><ul><li>工作目录（Working Directory）：我们的开发目录，只保存在项目目录下。</li><li>索引（Index）：暂存区域，工作目录下的文件add 后会在git 仓库中生成一个 blob 文件，当前索引指向暂存文件，这里的代码commit 后会被提交到本地仓库中</li><li>git 仓库：记录每次提交的快照及链式结构记录提交变更的历史</li><li>远程仓库：大家开发中协作的共享仓库</li></ul><p><img src="https://pic3.zhimg.com/80/v2-1ef6901abd53e03bdee03ba61af1a90a_720w.webp" alt="img"></p><p><em>ps：可参考以下博客有详细说明 -&gt;</em> <a href="https://zhuanlan.zhihu.com/p/96631135">腾讯技术工程：这才是真正的Git——Git内部原理揭秘！</a></p><h3 id="3-2-diff-命令"><a href="#3-2-diff-命令" class="headerlink" title="3.2 diff 命令"></a>3.2 diff 命令</h3><p>使用diff 命令，可以查看各个区的的文件差异</p><p><img src="https://pic1.zhimg.com/80/v2-28d9a00ae164ccd08e1ba600c86d9978_720w.webp" alt="img"></p><p>图片来自：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><ul><li><code>git diff 32942 88a2e</code></li><li><ul><li>两个commit之间的变化，执行结果如下</li></ul></li></ul><p><img src="https://pic2.zhimg.com/80/v2-c242bad4ebcef8389281b2e198fcdb69_720w.webp" alt="img"></p><ul><li><ul><li>使用tortoiseGit 看直观结果【Diff with previous version】</li></ul></li></ul><p><img src="https://pic4.zhimg.com/80/v2-0cc05ff4c78f7f9fe3ae8130b4753f43_720w.webp" alt="img"></p><ul><li><code>git diff --cached</code>查看 HEAD 位置到暂存(Index)位置的变化，也就是所有有执行add 操作的数据变化</li><li><ul><li>idea 中的蓝色文件改变部位标识+绿色新加文件</li></ul></li><li><code>git diff HEAD</code>工作区到 head 之间的文件变化</li><li><ul><li>使用tortoiseGit 看直观结果【Diff】</li></ul></li><li><code>git diff stable</code>工作区到 stable 分支的变化</li><li><code>git diff</code>工作区未 commit 的工作</li></ul><h2 id="4、git-分支"><a href="#4、git-分支" class="headerlink" title="4、git 分支"></a>4、git 分支</h2><p>git 分支的本质就是一个指向commit 的指针，或者说一个指向某一系列commit 之首的指针或引用。</p><h3 id="4-1、分支说明"><a href="#4-1、分支说明" class="headerlink" title="4.1、分支说明"></a>4.1、分支说明</h3><ul><li>分支git 分支信息保存在 <code>./git/refs</code> 文件夹下文件夹下的文件以分支名命名，打开文件可以直接看到commitId</li></ul><p><img src="https://pic3.zhimg.com/80/v2-c9a54574d7c31ff6169c15108ae2a7ae_720w.webp" alt="img"></p><ul><li>HEAD 指针<code>./git/HEAD 文件</code>HEAD 作用是记录当前工作区指向的commit，一般情况下 HEAD 指向一个分支，然后通过分支找到对应指向的 commit，如下HEAD 文件内容：代表当前工作区指向 develop 分支</li></ul><p><img src="https://pic4.zhimg.com/80/v2-50cc2dff3f766dbf9d785187de9c55eb_720w.webp" alt="img"></p><ul><li>标签（tag）tag 就像是给 commit 加一个不一样的别名，让这个 commit 变成一个里程碑节点。git 存在两种标签：轻量标签（lightweight）；附注标签（annotated）</li><li><ul><li>tag 对象内容见 2.5</li><li>查看所有标签git tag</li><li>对过去的提交打标签找到需要打标签的commitId，执行如下命令<code>git tag -a &lt;tagName&gt; &lt;commitId&gt;</code></li><li>push 标签push tagName 标签：<code>git push origin &lt;tagName&gt;</code>push 所有标签：<code>git push origin --tags</code></li><li>delete 标签删除远程标签：<code>git push origin --delete &lt;tagName&gt;</code>删除本地标签：<code>git tag -d &lt;tagName&gt;</code></li><li>检出标签代码<code>git checkout tagName</code>注意：该命令后仓库属于分支分离状态</li><li>轻量标签<code>git tag tagName</code>创建轻量标签，不需要使用 -a -s -m 选项，只需要提供标签名字</li><li>附注标签附注标签再git 数据库中存在一个完整的对象，其包含打标签者的名字、电子邮件、日期时间等信息</li><li><ul><li>创建命令:<code>git tag -a tagName -m &quot;tag comment&quot;</code></li><li>查看标签内容，附注标签包含的内容比较丰富:<code>git show tagName</code></li></ul></li></ul></li></ul><p><img src="https://pic4.zhimg.com/80/v2-93ddb710ee6eb37fd63d6969407115cb_720w.webp" alt="img"></p><ul><li>远程引用分支我们看到的 origin&#x2F;x.x.xx 都是远程引用分支。远程引用分支不能通过 commit 命令来更新，它为只读状态。Git 将这些远程引用作为记录远程服务器上各分支最后已知位置状态的书签来管理。</li></ul><h3 id="4-2-分支管理"><a href="#4-2-分支管理" class="headerlink" title="4.2 分支管理"></a>4.2 分支管理</h3><ul><li>查看所有分支<code>git branch</code></li><li>查看每一个分支的最后一次提交<code>git branch -v</code></li><li>查看哪些分支合并到当前分支<code>git branch --merged``git branch --merged &lt;branchName&gt;</code></li><li>查看哪些分支没有合并到当前分支<code>git branch --no-merged``git branch --no-merged &lt;branchName&gt;</code></li><li>创建分支</li><li><ul><li>在当前 HEAD 指向的commit 下创建一个新的分支<code>git branch &lt;branchName&gt;</code>创建新分支，并切到新分支<code>git checkout -b &lt;branchName&gt;</code></li></ul></li></ul><p><img src="https://pic4.zhimg.com/80/v2-534c53e949320f4cd6d717a6527e0797_720w.webp" alt="img"></p><ul><li>切分支：切到 master 分支<code>git checkout master</code></li><li>删除分支<code>git branch -d &lt;branchName&gt;</code></li><li>从指定 commit 出新建一个分支<code>git branch &lt;branchName&gt; &lt;commitId&gt;</code></li></ul><h3 id="4-3-跟踪分支（本地分支跟踪远程分支）"><a href="#4-3-跟踪分支（本地分支跟踪远程分支）" class="headerlink" title="4.3 跟踪分支（本地分支跟踪远程分支）"></a>4.3 跟踪分支（本地分支跟踪远程分支）</h3><p>将远程仓库中的分支拉取下来，本地会出现一个不可编辑的分支，类似 origin&#x2F;feature1.1.0，该分支其实就是对远程仓库分支当前情况的一个标记。</p><ul><li>创建一个本地分支跟踪远程分支<code>git chechout -b &lt;localBranchName&gt; &lt;remote&gt;/&lt;remoteBranchName&gt;</code></li><li>使用已有的本地分支跟踪远程分支<code>git branch -u &lt;remote&gt;/&lt;remoteBranchName&gt;</code></li><li>删除远程分支<code>git push origin --delete feature/1.0.0</code></li><li>clone 命令自动产生的 master 跟踪分支当使用 clone 命令克隆一个远程项目到本地，将会在本地产生一个 master 分支跟踪远程的 origin&#x2F;master 分支</li><li>查看设置的跟踪分支及其相关信息<code>git branch -vv</code></li></ul><p><img src="/" alt="img"></p><p>iss53 跟踪 origin&#x2F;iss53，【ahead 2】 代表本地有两个提交没有推送到服务器上master 分支正在跟踪 origin&#x2F;master 分支serverfix 分支正在跟踪 teamone 服务器上的 server-fix-good 分支，服务器上有一次提交还没有合并到本地同时本地有三次提交还没有推送到 teamone&#x2F;server-fix-good 分支testing 分支并没有跟踪任何远程分支<strong>注意：</strong>这些命令来自于本地分析，也就是本地仓库上已经拉取下来的的远程分支数据和本地分支数据进行比较。如果使用 pull 命令拉取数据，远程分支的数据会自动合并到本地分支(pull 类似 fetch+merge 或 fetch+rebase)，也就是说一般不会出现 behind 的情况，除非在分析前执行远程数据拉取，但不合并到本地分，如下：<code>git fetch --all</code></p><h3 id="4-4-commit-命令"><a href="#4-4-commit-命令" class="headerlink" title="4.4 commit 命令"></a>4.4 commit 命令</h3><p>命令：<code>git commit</code></p><ul><li>当前用户在main 分支下，在main 分支中执行commit 操作，创建一个新的commit 节点，新 commit 指向旧的commit 节点，分支和 HEAD 指向新的commit。</li></ul><p><img src="/" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><ul><li>如果用户在 stable 上分支上 commit，将产生如下效果</li></ul><p><img src="/" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><ul><li>创建一个新的 commit，将当前commit 取消，新的commit 替代（备注错误或追加代码时可用）命令：<code>git commit --amend -m &#39;comment&#39;</code><strong>注意</strong>：旧的commit 在 objects 中依然可以找到，但是没有任何指针指向该commit。后续git gc 时会将该commit 回收</li></ul><p><img src="/" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><p>idea 中commit 的时候勾上 Amend commit，实现以上命令效果</p><p><img src="/" alt="img"></p><h3 id="4-5-checkout-命令"><a href="#4-5-checkout-命令" class="headerlink" title="4.5 checkout 命令"></a>4.5 checkout 命令</h3><ul><li>如果工作区存在工作未commit 的工作，且工作内容和切换的目标分支有冲突，切换命令会执行失败</li></ul><p><img src="https://pic2.zhimg.com/80/v2-1605dab30396f7caf54c2baac21887d9_720w.webp" alt="img"></p><ul><li>切换失败可选两种处理方式</li><li><ul><li>force checkout丢弃当前工作区所有工作，切换到目标分支</li><li>smart Checkout先将当前工作区工作暂存，切换到分支后 push 出来，解决冲突，合并内容</li></ul></li><li>切换到指定 commit命令：<code>git checkout &lt;commitId&gt;</code></li></ul><p><img src="https://pic1.zhimg.com/80/v2-1e8c21cc142e3e7071421a5f80a040d0_720w.webp" alt="img"></p><p>切换时出现以上提醒，表示此时出现了head 分离的现象，也就是 HEAD 没有停留在任何分支上</p><p><img src="https://pic4.zhimg.com/80/v2-776f6bf56df2e29a4ca8cdf96f6db75f_720w.webp" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><p>如果此时进行了一次 commit，产生 2eecb</p><p><img src="https://pic1.zhimg.com/80/v2-a632c9a77abd6f8d144a81498ce220d4_720w.webp" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><p>将 HEAD 切换回main 分支后，2eecb commit 将没有任何指针引用，后续会丢失。</p><p><img src="https://pic4.zhimg.com/80/v2-4bd1786cf5ba86a97b320a4c84e07317_720w.webp" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><p>如果想保留 2eecb commit，需要在切换分支之前，在 2eecb commit 上创建一个新的分支指向它命令：<code>git checkout -b &lt;branchName&gt;</code></p><p><img src="https://pic2.zhimg.com/80/v2-94669361f4e0615c72eeaf67de68fe45_720w.webp" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><h3 id="4-6-reset-命令"><a href="#4-6-reset-命令" class="headerlink" title="4.6 reset 命令"></a>4.6 reset 命令</h3><p><img src="https://pic3.zhimg.com/80/v2-2ade18f3507509a7646827464f986286_720w.webp" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><ul><li><code>git reset [commitId] --soft</code>当使用 –soft 参数 reset 到 b325c 下，b325c 之后 commit 的内容(c10b9、da985、ed489)全部会留在工作区属于add 状态。分支 和 HEAD 都指向 b325c。</li><li><ul><li>相当于 tortoiseGit -&gt; show log 的 reset .. to this commit</li></ul></li><li><code>git reset [commitId] --hard</code>当使用 –hard reset 到 b325c 下，b325c 之后的提交将会全部消失，也不会停留在工作区。</li><li>***注意***：如果线上的 main 分支处于 ed489 的位置，以上两个命令执行后在进行新的commit，本地仓库会在 commit1 上产生一个子节点commitA。push 时候会让你跟远程 main 分支合并，此时如果确认 b325c 分支之后的commit 可以舍弃，使用 force push 强制推送，覆盖线上提交记录</li></ul><h3 id="4-7-merge-命令"><a href="#4-7-merge-命令" class="headerlink" title="4.7 merge 命令"></a>4.7 merge 命令</h3><p>执行 merge 命令时有两种情况：简单的移动指针(fast-forward)；三方合并</p><ul><li>三方合并在 main 分支下执行 <code>git merge other</code>生成一个新的 commit f8bc5，该commit 指向两个父节点（33104、f8bc5）。HEAD 和分支指针移动到新的 commit</li></ul><p><img src="https://pic4.zhimg.com/80/v2-2fca7f5794864c410d005c765f99a1bb_720w.webp" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><ul><li>简单的移动指针(fast-forward)如果 main 分支是 stable分支的祖父节点，stable 上执行 git merge main命令只是简单的移动 stable 分支指针到main 分支的端点。称为 fast-forward 合并</li></ul><p><img src="https://pic3.zhimg.com/80/v2-c3fa9201ba0dd66330f4526945d64c26_720w.webp" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><h3 id="4-8-cherry-pick-命令"><a href="#4-8-cherry-pick-命令" class="headerlink" title="4.8 cherry pick 命令"></a>4.8 cherry pick 命令</h3><p>命令：git cherry-pick <commitId></p><p><img src="https://pic1.zhimg.com/80/v2-184eb0a8ea60e514fb8e0abe35840fe0_720w.webp" alt="img"></p><p>图片来源：<a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase">https://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase</a></p><ul><li>cherry-pick 命令是 “复制” 一个提交节点并在当前分支做一次完全一样的新的提交注意：如果 cherry-pick 的commit 2c33a 对169a6 commit 没有依赖，则 169a6 的修改不会被携带过来。如果存在依赖关系修改会被携带并需要解决冲突。</li><li>idea 操作 cherry-pick切到需要合并的分支，找到 cherry-pick 的commit，执行 cherry-pick</li></ul><p><img src="https://pic4.zhimg.com/80/v2-b297f9b6ec84bd88cdfb023305f16faf_720w.webp" alt="img"></p><h3 id="4-9-rebase-命令"><a href="#4-9-rebase-命令" class="headerlink" title="4.9 rebase 命令"></a>4.9 rebase 命令</h3><ul><li><strong>两个分支的简单rebase 操作</strong>分支情况：在develop分支的 C2 commit上新建分支 feature&#x2F;1.1.0，并在分支上提交了 C3 C4。有其他人在 develop分支上提交了 C5</li></ul><p><img src="https://pic2.zhimg.com/80/v2-a56d5854d9c2626489acb86060bc0c71_720w.webp" alt="img"></p><p>将分支切到 feature&#x2F;1.1.0，执行<code>git rebase develop</code></p><p><img src="https://pic4.zhimg.com/80/v2-4e1a98412124e20afc403b133c33fe7b_720w.webp" alt="img"></p><p>将分支切到 develop，执行 <code>git merge feature/1.1.0</code> 。此时 develop 进行fast forward，直接将指针移动到 C4&#96;</p><p><img src="https://pic4.zhimg.com/80/v2-4420a32cfb7b2c72710239498acf64af_720w.webp" alt="img"></p><ul><li><strong>三个分支的 rebase 操作</strong>当前分支状况如下：master 分支C2 commit 下拉出 server 分支并提交 C3 C4 C5，server 分支C3 commit 下拉出 client 分支并提交C8 C9。master 在 C2 后提交了 C5 C6。分支情况及idea log 树如下：</li></ul><p><img src="https://pic2.zhimg.com/80/v2-2504a313184c47ccaa230f1dfed8abc5_720w.webp" alt="img"></p><p>分支情况</p><p><img src="https://pic4.zhimg.com/80/v2-e9648c9fe081937b927d5306e778154f_720w.webp" alt="img"></p><p>idea log 树</p><p>希望将 client 的 C8 C9 分支合并到 develop 分支，但是 server 的 C3 分支不合并：执行命令<code>git rebase --onto develop server client</code></p><p><img src="https://pic3.zhimg.com/80/v2-2a5c9ee19bed455a058767a782b9187a_720w.webp" alt="img"></p><p>分支情况</p><p><img src="https://pic2.zhimg.com/80/v2-515312f258545b3ee935d333c92cbc51_720w.webp" alt="img"></p><p>idea log 树</p><p>将client 合并到 develop：将分支切到 develop，执行<code>git merge client</code></p><p><img src="https://pic3.zhimg.com/80/v2-215d80f699d053561967a57b4fb2f582_720w.webp" alt="img"></p><p><img src="https://pic1.zhimg.com/80/v2-4ac95de25d740b9beee6b8370dd2156c_720w.webp" alt="img"></p><p>develop 合并server 分支，并删除 client 分支和 server 分支</p><p><img src="https://pic3.zhimg.com/80/v2-8ba0dad56b6e3f5e41beb39a26011872_720w.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-dde9ef0d9f25cd24d054472b7edc2535_720w.webp" alt="img"></p><ul><li><strong>什么情况下不适合用 rebase</strong>当你的代码已经提交到线上仓库，且你的代码已经被别人拉取合并了，千万不要进行 rebase，不然会出现如下混乱情况假设你仓库情况如下：远程master 分支指向 C1，本地 master 分支有两个提交 C2 和 C3</li></ul><p><strong><img src="https://pic4.zhimg.com/80/v2-09b1c5a85ca8813bbde6143bc0bc5bf3_720w.webp" alt="img"></strong></p><p>A同事在远程仓库上提交了 C5，B同事在远程仓库上提交了 C4 并合并了C5 产生了 C6 commit。远程仓库当前情况如下</p><p><strong><img src="https://pic1.zhimg.com/80/v2-2ec75e0df516978ec4b1f938e1563ca0_720w.webp" alt="img"></strong></p><p>此时你拉取远程仓库 master 分支到本地并进行一次合并，产生 C7 commit，你的本地仓库情况如下</p><p><strong><img src="https://pic4.zhimg.com/80/v2-b7ef2ecad9c1989cd9469e560f8c3687_720w.webp" alt="img"></strong></p><p>这时候B 同事决定不使用 merge，改用rebase，于是他把 C4 提交和 C6 合并回滚了，并rebase 了 C4，此时远程仓库变成了如下</p><p><img src="https://pic4.zhimg.com/80/v2-a6a4f4deadc1f10d71fa4a691939aa8b_720w.webp" alt="img"></p><p>此时你再次拉取远程仓库的数据，并进行了一次合并产生了C8 commit，你的本地仓库情况如下</p><p><img src="https://pic3.zhimg.com/80/v2-4a1c52ed30747738ce47b2d46582eb16_720w.webp" alt="img"></p><p>当你把你的本地仓库push 到远程仓库上，C4和C6 又回去了，并且C4 和 C4&#96; 的提交内容及提交者一样。惊喜不惊喜！！！！</p><ul><li><strong>rebase 和 merge 的区别</strong>当前情况：feature-1.1.0 从 dev 的 tt commit 中拉取，并由A 进行了 C2, C3 提交，B 在A 提交后拉取了feature-1.1.0 分支。</li></ul><p><img src="https://pic1.zhimg.com/80/v2-3aec370ca16e573ca7efd383177f0c48_720w.webp" alt="img"></p><p>线上异常，打了个补丁，dev 上加了一个 C1 提交</p><p><img src="https://pic2.zhimg.com/80/v2-897451264849f9d38c0853b5a8f1e789_720w.webp" alt="img"></p><p>A 在 feature-1.1.0 分支 rebase C1，并forcePush 到线上 feature-1.1.0 分支</p><p><img src="https://pic3.zhimg.com/80/v2-4a55a285a9e433c4b81735cc892d87d2_720w.webp" alt="img"></p><p>B 在原本状态下进行开发后本地提交了 C4</p><p><img src="https://pic3.zhimg.com/80/v2-3fef2faac0f867e0a7db264fc5b30b9a_720w.webp" alt="img"></p><p>此时B 进行拉取线上 feature-1.1.0 分支</p><p><img src="https://pic2.zhimg.com/80/v2-e9db4e8113905a9783f5d36f8e2e7759_720w.webp" alt="img"></p><p><img src="https://pic1.zhimg.com/80/v2-85557e96a6e209f155ef56500be25054_720w.webp" alt="img"></p><p>idea log 图，出现重复的 C2 和 C3</p><p><img src="/" alt="img"></p><p><img src="/" alt="img"></p><p>idea log 图，C2 和 C3 只出现一次</p><p><em>为什么此时的rebase 操作 C2<code>=C2，C3</code>&#x3D;C3 呢？</em>Git 除了对整个提交计算 SHA-1 校验和以外，也对本次提交所引入的修改进行计算——即 patch-id。所以不会再对 C2 和 C3 进行 rebase。当然，如果A 在进行 rebase 之前将 C2<code>和 C3</code> 的内容改变了，那就C2 和 C3 只能进行再次rebase</p><p>4.10 fatch 和 pull 命令</p><h2 id="5、常见的误操作回滚"><a href="#5、常见的误操作回滚" class="headerlink" title="5、常见的误操作回滚"></a>5、常见的误操作回滚</h2><h3 id="5-1-回滚-commit-操作"><a href="#5-1-回滚-commit-操作" class="headerlink" title="5.1 回滚 commit 操作"></a>5.1 回滚 commit 操作</h3><p>见 4.6 reset 命令</p><h3 id="5-2-reset-–hard-误操作回滚"><a href="#5-2-reset-–hard-误操作回滚" class="headerlink" title="5.2 reset –hard 误操作回滚"></a>5.2 reset –hard 误操作回滚</h3><ul><li><strong>前情提要</strong>使用<code>git log --pretty=oneline</code> 查看当前 dev 分支情况下如下</li></ul><p><img src="/" alt="img"></p><p>将其 reset 到 C3 提交<code>git reset --hard &lt;SHA-1&gt;</code></p><p><img src="/" alt="img"></p><p>再使用 <code>git log --pretty=oneline</code> 查看当前 dev 分支情况，C4、tt、C1 都消失了</p><p><img src="/" alt="img"></p><p>注意：因为dev 分支的reset操作没有push 到远程仓库，所以 origin&#x2F;dev 还是指向 C1，如果要让 origin&#x2F;dev 也指向C3，需要在 dev 分支上执行 force push</p><p><img src="/" alt="img"></p><p>此时你发现自己 reset 错了，怎么找回 C4、tt、C1 呢？</p><ul><li><strong>方法一：回滚 reflog 的 HEAD 撤销上次reset 操作</strong>git reflog 命令可以记录本地操作的所有日志，如下</li></ul><p><img src="/" alt="img"></p><p>可以看到我们的 reset 操作在 HEAD@{0} 处，这时候我们可以选择回滚 HEAD@{0} 操作，执行命令：<code>git reset --hard HEAD@&#123;1&#125;</code>将操作回滚到 HEAD@{1}</p><p><img src="/" alt="img"></p><p>回滚后再使用 <code>git log --pretty=oneline</code>查看当前 dev 分支情况，发现 C4、tt、C1 都回来了</p><p><img src="/" alt="img"></p><p>此时 <code>git reflog</code>可以看到多了一个执行记录，当然这个记录可能会让人看的有点懵</p><p><img src="/" alt="img"></p><ul><li><strong>方法二：找到被 hard reset 掉的commit，从该commit 上再拉取一个分支</strong>使用 <code>git log -g</code>可以找到C1 的commitId</li></ul><p><img src="/" alt="img"></p><p>从 C1 的commitId 拉取一个分支出来</p><p><img src="https://pic2.zhimg.com/80/v2-7853130cdd5ed7bb0b075f6e8f1d72f1_720w.webp" alt="img"></p><p>切分支到新拉取的 backup-branch 分支：<code>git checkout backup-branch</code></p><p><img src="https://pic3.zhimg.com/80/v2-09539f7c968e20db8afded808389315e_720w.webp" alt="img"></p><p>使用 <code>git log --pretty=oneline</code>查看当前 backup-branch 分支情况，与一开始的 dev 分支一致，C4、tt、C1 都回来了。并且可以看到当前分支 dev 指向 C3</p><p><img src="https://pic2.zhimg.com/80/v2-38c91dad4ff6daed48a8e4024e530831_720w.webp" alt="img"></p><h2 id="6、使用git-进行协作"><a href="#6、使用git-进行协作" class="headerlink" title="6、使用git 进行协作"></a>6、使用git 进行协作</h2><h3 id="6-1、集中式工作流-也叫单点协作模型（小团队开发最常用的模式）"><a href="#6-1、集中式工作流-也叫单点协作模型（小团队开发最常用的模式）" class="headerlink" title="6.1、集中式工作流 也叫单点协作模型（小团队开发最常用的模式）"></a>6.1、集中式工作流 也叫单点协作模型（小团队开发最常用的模式）</h3><p>一个中央仓库统一管理代码代码，所有人将自己的工作同步到中央仓库，也可从中央仓库拉取代码。当开发者操作将代码push 到中央仓库时，如果无法进行 fast-forward，需要先拉取中央仓库的代码合并到本地，合并完成后，再执行push</p><p><img src="https://pic1.zhimg.com/80/v2-7ef26163cf6262c486e3aecfd04a1498_720w.webp" alt="img"></p><h3 id="6-2、集成管理者工作流-也叫多仓库工作流（开源项目最常用的模式）"><a href="#6-2、集成管理者工作流-也叫多仓库工作流（开源项目最常用的模式）" class="headerlink" title="6.2、集成管理者工作流 也叫多仓库工作流（开源项目最常用的模式）"></a>6.2、集成管理者工作流 也叫多仓库工作流（开源项目最常用的模式）</h3><p>开源项目一般有一个“官方”的权威仓库，这个仓库中的代码绝对是稳定版本，这种仓库存在权威的项目维护者，只有该维护者才有权力将代码合并到权威仓库。那么，如果有其他人想要贡献代码到该仓库中该如何操作呢？</p><ul><li><strong>仓库命名</strong>blessed repository：权威仓库integration manager：项目维护者developer public：贡献者公共仓库developer private：贡献则私有仓库</li><li><strong>权限仓库管理流程</strong></li><li><ul><li>项目维护者将项目推送到权威仓库</li><li>项目贡献者克隆此仓库并贡献代码，对项目做出修改</li><li>项目贡献者将修改后的数据推送到自己的公开仓库</li><li>项目贡献者发邮件给项目维护者，请求拉取自己的更新</li><li>项目维护者在自己的本地仓库中将贡献者的公共仓库加为远程仓库，并合修改并校验</li><li>项目维护者将合并后的修改推送动权威仓库，贡献者代码生效</li></ul></li></ul><p><img src="https://pic1.zhimg.com/80/v2-801ede94a0df884ada825b6c50933e80_720w.webp" alt="img"></p><h3 id="6-3、主管与副主管工作流"><a href="#6-3、主管与副主管工作流" class="headerlink" title="6.3、主管与副主管工作流"></a>6.3、主管与副主管工作流</h3><p>这种方式是多仓库工作流的变种，一般拥有数百位协作开发者的超大型项目才会用到这种工作方式，如 Linux 内核开发。</p><ul><li>具体协作流程</li><li><ul><li>blessed repository 为最终仓库，该仓库的代码只能由主管(dictator) 进行推送，其他人只读</li><li>普通开发者拉取 blessed repository 仓库中的代码进行开发，并根据 blessed repository 的 master 分支进行 rebase</li><li>副主管(lieutenant) 将普通开发者的代码合并到自己的 master 分支，并根据 blessed repository 的 master 分支进行 rebase</li><li>最后主管(dictator) 集成副主管的 master 分支代码，并推送到 blessed repository 仓库中</li></ul></li></ul><p><img src="https://pic3.zhimg.com/80/v2-7de76fc3fd69a7259e60f50a939167a2_720w.webp" alt="img"></p><h3 id="6-4、简单项目开发和发布的分支管理及流程"><a href="#6-4、简单项目开发和发布的分支管理及流程" class="headerlink" title="6.4、简单项目开发和发布的分支管理及流程"></a>6.4、简单项目开发和发布的分支管理及流程</h3><p>1、使用主题分支 ruby_client 进行开发</p><p><img src="https://pic2.zhimg.com/80/v2-55fb6b3597df1353a4772a531b71a905_720w.webp" alt="img"></p><p>2、开发完成后将主题分支合并到 develop 分支提测和回归</p><p><img src="https://pic2.zhimg.com/80/v2-e8ec381fade7869b2a5984ee734bf905_720w.webp" alt="img"></p><p>3、使用 develop 分支发布，发布完成版本稳定后，将 master 分支 fast-forward 到develop 最新 commit。此时可以在master 分支上拉出新的分支进行新的迭代</p><p><img src="https://pic4.zhimg.com/80/v2-9d631a462b8eb5a791820f779295592b_720w.webp" alt="img"></p><h2 id="参照文档："><a href="#参照文档：" class="headerlink" title="参照文档："></a>参照文档：</h2><p><a href="https://link.zhihu.com/?target=https://git-scm.com/docs">Git - Reference</a><a href="https://link.zhihu.com/?target=https://git-scm.com/book/zh/v2">Git - Book</a><a href="https://zhuanlan.zhihu.com/p/96631135">腾讯技术工程：这才是真正的Git——Git内部原理揭秘！</a><a href="https://link.zhihu.com/?target=https://marklodato.github.io/visual-git-guide/index-zh-cn.html%23rebase">图解Git</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>XXL-JOB 分布式调度</title>
      <link href="/2023/06/30/XXL-JOB-%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6/"/>
      <url>/2023/06/30/XXL-JOB-%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>在平时的业务场景中，经常有一些场景需要使用定时任务，比如：</p><ul><li>时间驱动的场景：某个时间点发送优惠券，发送短信等等。</li><li>批量处理数据：批量统计上个月的账单，统计上个月销售数据等等。</li><li>固定频率的场景：每隔5分钟需要执行一次。</li></ul><p>所以定时任务在平时开发中并不少见，而且对于现在快速消费的时代，每天都需要发送各种推送，消息都需要依赖定时任务去完成，应用非常广泛。</p><h1 id="二、为什么需要任务调度平台"><a href="#二、为什么需要任务调度平台" class="headerlink" title="二、为什么需要任务调度平台"></a>二、为什么需要任务调度平台</h1><p>在Java中，传统的定时任务实现方案，比如Timer，Quartz等都或多或少存在一些问题：</p><ul><li>不支持集群、不支持统计、没有管理平台、没有失败报警、没有监控等等</li></ul><p>而且在现在分布式的架构中，有一些场景需要分布式任务调度：</p><ul><li>同一个服务多个实例的任务存在互斥时，需要统一的调度。</li><li>任务调度需要支持高可用、监控、故障告警。</li><li>需要统一管理和追踪各个服务节点任务调度的结果，需要记录保存任务属性信息等。</li></ul><p>显然传统的定时任务已经不满足现在的分布式架构，所以需要一个分布式任务调度平台，目前比较主流的是elasticjob和xxl-job。</p><p>elasticjob由当当网开源，目前github有6.5k的Star，使用的公司在官网登记有76家。</p><p><img src="C:\Users\16430\AppData\Roaming\Typora\typora-user-images\image-20230630221355357.png" alt="image-20230630221355357"></p><p>跟xxl-job不同的是，<strong>elasticjob是采用zookeeper实现分布式协调</strong>，实现任务高可用以及分片。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221413397.png" alt="image-20230630221413397"></p><h1 id="三、为什么选择XXL-JOB"><a href="#三、为什么选择XXL-JOB" class="headerlink" title="三、为什么选择XXL-JOB"></a>三、为什么选择XXL-JOB</h1><p>实际上更多公司选择xxl-job，目前<strong>xxl-job的github上有15.7k个star，登记公司有348个</strong>。毫无疑问elasticjob和xxl-job都是非常优秀的技术框架，接下来我们进一步对比讨论，探索一下为什么更多公司会选择xxl-job。</p><p>首先先介绍一下xxl-job，这是出自大众点评许雪里(xxl就是作者名字的拼音首字母)的开源项目，官网上介绍这是一个轻量级分布式任务调度框架，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。跟elasticjob不同，xxl-job环境依赖于mysql，不用ZooKeeper，这也是最大的不同。</p><p>elasticjob的初衷是为了面对高并发复杂的业务，即使是在业务量大，服务器多的时候也能做好任务调度，尽可能的利用服务器的资源。使用ZooKeeper使其具有高可用、一致性的，而且还具有良好的扩展性。官网上写<strong>elasticjob是无中心化的，通过ZooKeeper的选举机制选举出主服务器，如果主服务器挂了，会重新选举新的主服务器。因此elasticjob具有良好的扩展性和可用性，但是使用和运维有一定的复杂</strong>。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221432275.png" alt="image-20230630221432275">xxl-job则相反，是通过一个中心式的调度平台，调度多个执行器执行任务，调度中心通过DB锁保证集群分布式调度的一致性，这样扩展执行器会增大DB的压力，但是如果实际上这里数据库只是负责任务的调度执行。但是如果没有大量的执行器的话和任务的情况，是不会造成数据库压力的。实际上大部分公司任务数，执行器并不多(虽然面试经常会问一些高并发的问题)。</p><p>相对来说，xxl-job中心式的调度平台<strong>轻量级，开箱即用，操作简易，上手快，与SpringBoot有非常好的集成</strong>，而且监控界面就集成在调度中心，界面又简洁，对于<strong>企业维护起来成本不高，还有失败的邮件告警</strong>等等。这就使很多企业选择xxl-job做调度平台。</p><h1 id="四、安装"><a href="#四、安装" class="headerlink" title="四、安装"></a>四、安装</h1><h2 id="4-1-拉取源码"><a href="#4-1-拉取源码" class="headerlink" title="4.1 拉取源码"></a>4.1 拉取源码</h2><p>搭建xxl-job很简单，有docker拉取镜像部署和源码编译两种方式，docker部署的方式比较简单，我就讲源码编译的方式。首先到github拉取xxl-job源码到本地。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221447639.png" alt="image-20230630221447639"></p><h2 id="4-2-导入IDEA"><a href="#4-2-导入IDEA" class="headerlink" title="4.2 导入IDEA"></a>4.2 导入IDEA</h2><p>拉取源码下来后，可以看到项目结构，如下：</p><p><img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221459046.png" alt="image-20230630221459046"></p><p>导入到IDEA，配置一下Maven，下载相关的jar包，稍等一下后，就可以看到这样的项目：</p><p><img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221511795.png" alt="image-20230630221511795"></p><h2 id="4-3-初始化数据库"><a href="#4-3-初始化数据库" class="headerlink" title="4.3 初始化数据库"></a>4.3 初始化数据库</h2><p>前面讲过xxl-job需要依赖mysql，所以需要初始化数据库，在xxl-jobdocdb路径下找到tables_xxl_job.sql文件。在mysql上运行sql文件。</p><p><img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221522366.png" alt="image-20230630221522366"></p><h2 id="4-4-配置文件"><a href="#4-4-配置文件" class="headerlink" title="4.4 配置文件"></a>4.4 配置文件</h2><p>接着就改一下配置文件，在admin项目下找到application.properties文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">### 调度中心JDBC链接</span><br><span class="line">spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghai</span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=</span><br><span class="line">spring.datasource.driver-class-name=com.mysql.jdbc.Driver</span><br><span class="line">### 报警邮箱</span><br><span class="line">spring.mail.host=smtp.qq.com</span><br><span class="line">spring.mail.port=25</span><br><span class="line">spring.mail.username=xxx@qq.com</span><br><span class="line">spring.mail.password=xxx</span><br><span class="line">spring.mail.properties.mail.smtp.auth=true</span><br><span class="line">spring.mail.properties.mail.smtp.starttls.enable=true</span><br><span class="line">spring.mail.properties.mail.smtp.starttls.required=true</span><br><span class="line">spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory</span><br><span class="line">### 调度中心通讯TOKEN [选填]：非空时启用；</span><br><span class="line">xxl.job.accessToken=</span><br><span class="line">### 调度中心国际化配置 [必填]： 默认为 &quot;zh_CN&quot;/中文简体, 可选范围为 &quot;zh_CN&quot;/中文简体, &quot;zh_TC&quot;/中文繁体 and &quot;en&quot;/英文；</span><br><span class="line">xxl.job.i18n=zh_CN</span><br><span class="line">## 调度线程池最大线程配置【必填】</span><br><span class="line">xxl.job.triggerpool.fast.max=200</span><br><span class="line">xxl.job.triggerpool.slow.max=100</span><br><span class="line">### 调度中心日志表数据保存天数 [必填]：过期日志自动清理；限制大于等于7时生效，否则, 如-1，关闭自动清理功能；</span><br><span class="line">xxl.job.logretentiondays=10</span><br></pre></td></tr></table></figure><h2 id="4-5-编译运行"><a href="#4-5-编译运行" class="headerlink" title="4.5 编译运行"></a>4.5 编译运行</h2><p>简单一点直接跑admin项目的main方法启动也行。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221607806.png" alt="image-20230630221607806">如果部署在服务器呢，那我们需要打包成jar包，在IDEA利用Maven插件打包。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221620536.png" alt="image-20230630221620536">然后在xxl-jobxxl-job-admintarget路径下，找到jar包。</p><p><img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221631331.png" alt="image-20230630221631331"></p><p>然后就得到jar包了，使用java -jar命令就可以启动了。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630230050798.png" alt="image-20230630230050798">到这里就已经完成了！打开浏览器，输入<a href="http://localhost:8080/xxl-job-admin%E8%BF%9B%E5%85%A5%E7%AE%A1%E7%90%86%E9%A1%B5%E9%9D%A2%E3%80%82%E9%BB%98%E8%AE%A4%E8%B4%A6%E5%8F%B7/%E5%AF%86%E7%A0%81%EF%BC%9Aadmin/123456%E3%80%82![image-20230630221652276](https://raw.githubusercontent.com/cyx27/image/main/image-20230630221652276.png)">http://localhost:8080/xxl-job-admin进入管理页面。默认账号/密码：admin/123456。![image-20230630221652276](https://raw.githubusercontent.com/cyx27/image/main/image-20230630221652276.png)</a></p><h1 id="五、永远的HelloWord"><a href="#五、永远的HelloWord" class="headerlink" title="五、永远的HelloWord"></a>五、永远的HelloWord</h1><p>部署了调度中心之后，需要往调度中心注册执行器，添加调度任务。接下来就参考xxl-job写一个简单的例子。</p><p>首先创建一个SpringBoot项目，名字叫”xxljob-demo”，添加依赖。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;&lt;!-- 官网的demo是2.2.1，中央maven仓库还没有，所以就用2.2.0 --&gt;</span><br><span class="line">        &lt;groupId&gt;com.xuxueli&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;2.2.0&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure><p>接着修改application.properties。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># web port</span><br><span class="line">server.port=8081</span><br><span class="line"># log config</span><br><span class="line">logging.config=classpath:logback.xml</span><br><span class="line">spring.application.name=xxljob-demo</span><br><span class="line">### 调度中心部署跟地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行&quot;执行器心跳注册&quot;和&quot;任务结果回调&quot;；为空则关闭自动注册；</span><br><span class="line">xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin</span><br><span class="line">### 执行器通讯TOKEN [选填]：非空时启用；</span><br><span class="line">xxl.job.accessToken=</span><br><span class="line">### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册</span><br><span class="line">xxl.job.executor.appname=xxl-job-demo</span><br><span class="line">### 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。</span><br><span class="line">xxl.job.executor.address=</span><br><span class="line">### 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；地址信息用于 &quot;执行器注册&quot; 和 &quot;调度中心请求并触发任务&quot;；</span><br><span class="line">xxl.job.executor.ip=</span><br><span class="line">### 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；</span><br><span class="line">xxl.job.executor.port=9999</span><br><span class="line">### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；</span><br><span class="line">xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler</span><br><span class="line">### 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；</span><br><span class="line">xxl.job.executor.logretentiondays=10</span><br></pre></td></tr></table></figure><p>接着写一个配置类XxlJobConfig。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class XxlJobConfig &#123;</span><br><span class="line">    private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class);</span><br><span class="line">    @Value(&quot;$&#123;xxl.job.admin.addresses&#125;&quot;)</span><br><span class="line">    private String adminAddresses;</span><br><span class="line">    @Value(&quot;$&#123;xxl.job.accessToken&#125;&quot;)</span><br><span class="line">    private String accessToken;</span><br><span class="line">    @Value(&quot;$&#123;xxl.job.executor.appname&#125;&quot;)</span><br><span class="line">    private String appname;</span><br><span class="line">    @Value(&quot;$&#123;xxl.job.executor.address&#125;&quot;)</span><br><span class="line">    private String address;</span><br><span class="line">    @Value(&quot;$&#123;xxl.job.executor.ip&#125;&quot;)</span><br><span class="line">    private String ip;</span><br><span class="line">    @Value(&quot;$&#123;xxl.job.executor.port&#125;&quot;)</span><br><span class="line">    private int port;</span><br><span class="line">    @Value(&quot;$&#123;xxl.job.executor.logpath&#125;&quot;)</span><br><span class="line">    private String logPath;</span><br><span class="line">    @Value(&quot;$&#123;xxl.job.executor.logretentiondays&#125;&quot;)</span><br><span class="line">    private int logRetentionDays;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public XxlJobSpringExecutor xxlJobExecutor() &#123;</span><br><span class="line">        logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.&quot;);</span><br><span class="line">        XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();</span><br><span class="line">        xxlJobSpringExecutor.setAdminAddresses(adminAddresses);</span><br><span class="line">        xxlJobSpringExecutor.setAppname(appname);</span><br><span class="line">        xxlJobSpringExecutor.setAddress(address);</span><br><span class="line">        xxlJobSpringExecutor.setIp(ip);</span><br><span class="line">        xxlJobSpringExecutor.setPort(port);</span><br><span class="line">        xxlJobSpringExecutor.setAccessToken(accessToken);</span><br><span class="line">        xxlJobSpringExecutor.setLogPath(logPath);</span><br><span class="line">        xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays);</span><br><span class="line">        return xxlJobSpringExecutor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着编写一个任务类XxlJobDemoHandler，使用Bean模式。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class XxlJobDemoHandler &#123;</span><br><span class="line">    /**</span><br><span class="line">     * Bean模式，一个方法为一个任务</span><br><span class="line">     * 1、在Spring Bean实例中，开发Job方法，方式格式要求为 &quot;public ReturnT&lt;String&gt; execute(String param)&quot;</span><br><span class="line">     * 2、为Job方法添加注解 &quot;@XxlJob(value=&quot;自定义jobhandler名称&quot;, init = &quot;JobHandler初始化方法&quot;, destroy = &quot;JobHandler销毁方法&quot;)&quot;，注解value值对应的是调度中心新建任务的JobHandler属性的值。</span><br><span class="line">     * 3、执行日志：需要通过 &quot;XxlJobLogger.log&quot; 打印执行日志；</span><br><span class="line">     */</span><br><span class="line">    @XxlJob(&quot;demoJobHandler&quot;)</span><br><span class="line">    public ReturnT&lt;String&gt; demoJobHandler(String param) throws Exception &#123;</span><br><span class="line">        XxlJobLogger.log(&quot;java, Hello World~~~&quot;);</span><br><span class="line">        XxlJobLogger.log(&quot;param:&quot; + param);</span><br><span class="line">        return ReturnT.SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在resources目录下，添加logback.xml文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;configuration debug=&quot;false&quot; scan=&quot;true&quot; scanPeriod=&quot;1 seconds&quot;&gt;</span><br><span class="line">    &lt;contextName&gt;logback&lt;/contextName&gt;</span><br><span class="line">    &lt;property name=&quot;log.path&quot; value=&quot;/data/applogs/xxl-job/xxl-job-executor-sample-springboot.log&quot;/&gt;</span><br><span class="line">    &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;</span><br><span class="line">        &lt;encoder&gt;</span><br><span class="line">            &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt;</span><br><span class="line">        &lt;/encoder&gt;</span><br><span class="line">    &lt;/appender&gt;</span><br><span class="line">    &lt;appender name=&quot;file&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;</span><br><span class="line">        &lt;file&gt;$&#123;log.path&#125;&lt;/file&gt;</span><br><span class="line">        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;</span><br><span class="line">            &lt;fileNamePattern&gt;$&#123;log.path&#125;.%d&#123;yyyy-MM-dd&#125;.zip&lt;/fileNamePattern&gt;</span><br><span class="line">        &lt;/rollingPolicy&gt;</span><br><span class="line">        &lt;encoder&gt;</span><br><span class="line">            &lt;pattern&gt;%date %level [%thread] %logger&#123;36&#125; [%file : %line] %msg%n</span><br><span class="line">            &lt;/pattern&gt;</span><br><span class="line">        &lt;/encoder&gt;</span><br><span class="line">    &lt;/appender&gt;</span><br><span class="line">    &lt;root level=&quot;info&quot;&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;console&quot;/&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;file&quot;/&gt;</span><br><span class="line">    &lt;/root&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>写完之后启动服务，然后可以打开管理界面，找到执行器管理，添加执行器。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221711851.png" alt="image-20230630221711851">接着到任务管理，添加任务。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221723299.png" alt="image-20230630221723299"><img src="C:\Users\16430\AppData\Roaming\Typora\typora-user-images\image-20230630221733599.png" alt="image-20230630221733599">最后我们可以到任务管理去测试一下，运行demoJobHandler。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221757433.png" alt="image-20230630221757433"><img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221816255.png" alt="image-20230630221816255">点击保存后，会立即执行。点击查看日志，可以看到任务执行的历史日志记录。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221827303.png" alt="image-20230630221827303">打开刚刚执行的执行日志，我们可以看到，运行成功。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221835017.png" alt="image-20230630221835017">)这就是简单的Demo演示，非常简单，上手也快。</p><h1 id="六、谈谈架构设计"><a href="#六、谈谈架构设计" class="headerlink" title="六、谈谈架构设计"></a>六、谈谈架构设计</h1><p>下面简单地说一下xxl-job的架构，我们先看官网提供的一张架构图来分析。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221845913.png" alt="image-20230630221845913">)从架构图可以看出，分别有调度中心和执行器两大组成部分</p><ul><li>调度中心。负责<strong>管理调度信息</strong>，按照调度配置发出调度请求，自身不承担业务代码。支持可视化界面，可以在调度中心对任务进行新增，更新，删除，会实时生效。支持监控调度结果，查看执行日志，查看调度任务统计报表，任务失败告警等等。</li><li>执行器。负责接收调度请求，执行调度任务的业务逻辑。执行器启动后需要注册到调度中心。接收调度中心的发出的执行请求，终止请求，日志请求等等。</li></ul><p>接下来我们看一下xxl-job的工作原理。<img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221853822.png" alt="image-20230630221853822"></p><ul><li>任务执行器根据配置的调度中心的地址，自动注册到调度中心。</li><li>达到任务触发条件，调度中心下发任务。</li><li>执行器基于线程池执行任务，并把执行结果放入内存队列中、把执行日志写入日志文件中。</li><li>执行器的回调线程消费内存队列中的执行结果，主动上报给调度中心。</li><li>当用户在调度中心查看任务日志，调度中心请求任务执行器，任务执行器读取任务日志文件并返回日志详情。</li></ul><p>原文链接：<a href="https://developer.aliyun.com/article/775305">https://developer.aliyun.com/article/775305</a></p><p>Github 地址：<a href="https://github.com/yehongzhi/learningSummary?spm=a2c6h.12873639.article-detail.4.6fdf7e4btfCyVA">https://github.com/yehongzhi/learningSummary</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统 - 全局唯一ID实现方案</title>
      <link href="/2023/06/30/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80ID%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88/"/>
      <url>/2023/06/30/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80ID%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<h2 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h2><p><code>UUID （Universally Unique Identifier）</code>，通用唯一识别码的缩写。UUID是由一组32位数的16进制数字所构成，所以UUID理论上的总数为 <code>16^32=2^128</code>，约等于 <code>3.4 x 10^38</code>。也就是说若每纳秒产生1兆个UUID，要花100亿年才会将所有UUID用完。</p><p>生成的UUID是由 8-4-4-4-12格式的数据组成，其中32个字符和4个连字符’ - ‘，一般我们使用的时候会将连字符删除 uuid.<code>toString().replaceAll(&quot;-&quot;,&quot;&quot;)</code>。</p><p>目前UUID的产生方式有5种版本，每个版本的算法不同，应用范围也不同。</p><ul><li><code>基于时间的UUID</code> - 版本1： 这个一般是通过当前时间，随机数，和本地Mac地址来计算出来，可以通过 org.apache.logging.log4j.core.util包中的 UuidUtil.getTimeBasedUuid()来使用或者其他包中工具。由于使用了MAC地址，因此能够确保唯一性，但是同时也暴露了MAC地址，私密性不够好。</li><li><code>DCE安全的UUID</code> - 版本2 DCE（Distributed Computing Environment）安全的UUID和基于时间的UUID算法相同，但会把时间戳的前4位置换为POSIX的UID或GID。这个版本的UUID在实际中较少用到。</li><li><code>基于名字的UUID（MD5）</code>- 版本3 基于名字的UUID通过计算名字和名字空间的MD5散列值得到。这个版本的UUID保证了：相同名字空间中不同名字生成的UUID的唯一性；不同名字空间中的UUID的唯一性；相同名字空间中相同名字的UUID重复生成是相同的。</li><li><code>随机UUID</code> - 版本4 根据随机数，或者伪随机数生成UUID。这种UUID产生重复的概率是可以计算出来的，但是重复的可能性可以忽略不计，因此该版本也是被经常使用的版本。JDK中使用的就是这个版本。</li><li><code>基于名字的UUID（SHA1）</code> - 版本5 和基于名字的UUID算法类似，只是散列值计算使用SHA1（Secure Hash Algorithm 1）算法。</li></ul><p>虽然 UUID 生成方便，本地生成没有网络消耗，但是使用起来也有一些缺点，</p><ul><li><strong>不易于存储</strong>：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。</li><li><strong>信息不安全</strong>：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，暴露使用者的位置。</li><li><strong>对MySQL索引不利</strong>：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。</li></ul><h2 id="数据库生成"><a href="#数据库生成" class="headerlink" title="数据库生成"></a>数据库生成</h2><p>是不是一定要基于外界的条件才能满足分布式唯一ID的需求呢，我们能不能在我们分布式数据库的基础上获取我们需要的ID？</p><p>由于分布式数据库的起始自增值一样所以才会有冲突的情况发生，那么我们将分布式系统中数据库的同一个业务表的自增ID设计成不一样的起始值，然后设置固定的步长，步长的值即为分库的数量或分表的数量。</p><p>以MySQL举例，利用给字段设置<code>auto_increment_increment</code>和<code>auto_increment_offset</code>来保证ID自增。</p><ul><li><code>auto_increment_offset</code>：表示自增长字段从那个数开始，他的取值范围是1 .. 65535。</li><li><code>auto_increment_increment</code>：表示自增长字段每次递增的量，其默认值是1，取值范围是1 .. 65535。</li></ul><p>假设有三台机器，则DB1中order表的起始ID值为1，DB2中order表的起始值为2，DB3中order表的起始值为3，它们自增的步长都为3，则它们的ID生成范围如下图所示：</p><p><img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221935442.png" alt="image-20230630221935442"></p><p>通过这种方式明显的优势就是依赖于数据库自身不需要其他资源，并且ID号单调自增，可以实现一些对ID有特殊要求的业务。</p><p>但是缺点也很明显，首先它<strong>强依赖DB</strong>，当DB异常时整个系统不可用。虽然配置主从复制可以尽可能的增加可用性，但是<strong>数据一致性在特殊情况下难以保证</strong>。主从切换时的不一致可能会导致重复发号。还有就是<strong>ID发号性能瓶颈限制在单台MySQL的读写性能</strong>。</p><h2 id="使用redis实现"><a href="#使用redis实现" class="headerlink" title="使用redis实现"></a>使用redis实现</h2><p>Redis实现分布式唯一ID主要是通过提供像 <code>INCR</code> 和 <code>INCRBY</code> 这样的自增原子命令，由于Redis自身的单线程的特点所以能保证生成的 ID 肯定是唯一有序的。</p><p>但是单机存在性能瓶颈，无法满足高并发的业务需求，所以可以采用集群的方式来实现。集群的方式又会涉及到和数据库集群同样的问题，所以也需要设置分段和步长来实现。</p><p>为了避免长期自增后数字过大可以通过与当前时间戳组合起来使用，另外为了保证并发和业务多线程的问题可以采用 Redis + Lua的方式进行编码，保证安全。</p><p>Redis 实现分布式全局唯一ID，它的性能比较高，生成的数据是有序的，对排序业务有利，但是同样它依赖于redis，<strong>需要系统引进redis组件，增加了系统的配置复杂性</strong>。</p><p>当然现在Redis的使用性很普遍，所以如果其他业务已经引进了Redis集群，则可以资源利用考虑使用Redis来实现。</p><h2 id="雪花算法-Snowflake"><a href="#雪花算法-Snowflake" class="headerlink" title="雪花算法-Snowflake"></a>雪花算法-Snowflake</h2><p>Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。而 Java中64bit的整数是Long类型，所以在 Java 中 SnowFlake 算法生成的 ID 就是 long 来存储的。</p><ul><li><strong>第1位</strong>占用1bit，其值始终是0，可看做是符号位不使用。</li><li><strong>第2位</strong>开始的41位是时间戳，41-bit位可表示2^41个数，每个数代表毫秒，那么雪花算法可用的时间年限是<code>(1L&lt;&lt;41)/(1000L360024*365)</code>&#x3D;69 年的时间。</li><li><strong>中间的10-bit位</strong>可表示机器数，即2^10 &#x3D; 1024台机器，但是一般情况下我们不会部署这么台机器。如果我们对IDC（互联网数据中心）有需求，还可以将 10-bit 分 5-bit 给 IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，具体的划分可以根据自身需求定义。</li><li><strong>最后12-bit位</strong>是自增序列，可表示2^12 &#x3D; 4096个数。</li></ul><p>这样的划分之后相当于<strong>在一毫秒一个数据中心的一台机器上可产生4096个有序的不重复的ID</strong>。但是我们 IDC 和机器数肯定不止一个，所以毫秒内能生成的有序ID数是翻倍的。</p><p><img src="https://raw.githubusercontent.com/cyx27/image/main/image-20230630221944230.png" alt="image-20230630221944230"></p><p><strong>雪花算法提供了一个很好的设计思想，雪花算法生成的ID是趋势递增，不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的，而且可以根据自身业务特性分配bit位，非常灵活</strong>。</p><p>但是雪花算法强<strong>依赖机器时钟</strong>，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。如果恰巧回退前生成过一些ID，而时间回退后，生成的ID就有可能重复。官方对于此并没有给出解决方案，而是简单的抛错处理，这样会造成在时间被追回之前的这段时间服务不可用。</p><p>很多其他类雪花算法也是在此思想上的设计然后改进规避它的缺陷，后面介绍的<code>百度 UidGenerator</code> 和 <code>美团分布式ID生成系统 Leaf</code> 中snowflake模式都是在 snowflake 的基础上演进出来的。</p><h3 id="薄雾算法的设计思路是怎么样的？"><a href="#薄雾算法的设计思路是怎么样的？" class="headerlink" title="薄雾算法的设计思路是怎么样的？"></a>薄雾算法的设计思路是怎么样的？</h3><p>薄雾算法采用了与 snowflake 相同的位数——64，在考量业务场景和要求后并没有沿用 1-41-10-12 的占位，而是采用了 1-47-8-8 的占位。即：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">* 1      2                                                     48         56       64</span><br><span class="line">* +------+-----------------------------------------------------+----------+----------+</span><br><span class="line">* retain | increas                                             | salt     | salt |</span><br><span class="line">* +------+-----------------------------------------------------+----------+----------+</span><br><span class="line">* 0      | 0000000000 0000000000 0000000000 0000000000 0000000 | 00000000 | 00000000 |</span><br><span class="line">* +------+-----------------------------------------------------+------------+--------+</span><br></pre></td></tr></table></figure><ul><li>第一段为最高位，占 1 位，保持为 0，使得值永远为正数；</li><li>第二段放置自增数，占 47 位，自增数在高位能保证结果值呈递增态势，遂低位可以为所欲为；</li><li>第三段放置随机因子一，占 8 位，上限数值 255，使结果值不可预测；</li><li>第四段放置随机因子二，占 8 位，上限数值 255，使结果值不可预测；</li></ul><h3 id="薄雾算法生成的数值是什么样的？"><a href="#薄雾算法生成的数值是什么样的？" class="headerlink" title="# 薄雾算法生成的数值是什么样的？"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95%E7%94%9F%E6%88%90%E7%9A%84%E6%95%B0%E5%80%BC%E6%98%AF%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84">#</a> 薄雾算法生成的数值是什么样的？</h3><p>薄雾自增数为 1～10 的运行结果类似如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">171671</span><br><span class="line">250611</span><br><span class="line">263582</span><br><span class="line">355598</span><br><span class="line">427749</span><br><span class="line">482010</span><br><span class="line">581550</span><br><span class="line">644278</span><br><span class="line">698636</span><br><span class="line">762474</span><br></pre></td></tr></table></figure><p>根据运行结果可知，薄雾算法能够满足“全局不重复，不可猜测且呈递增态势”的场景要求。</p><h3 id="薄雾算法-mist-和雪花算法-snowflake-有何区别？"><a href="#薄雾算法-mist-和雪花算法-snowflake-有何区别？" class="headerlink" title="# 薄雾算法 mist 和雪花算法 snowflake 有何区别？"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95-mist-%E5%92%8C%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95-snowflake-%E6%9C%89%E4%BD%95%E5%8C%BA%E5%88%AB">#</a> 薄雾算法 mist 和雪花算法 snowflake 有何区别？</h3><p>snowflake 是由 Twitter 公司提出的一种全局唯一 ID 生成算法，它具有“递增态势、不依赖数据库、高性能”等特点，自 snowflake 推出以来备受欢迎，算法被应用于大大小小公司的服务中。snowflake 高位为时间戳的二进制，遂完全受到时间戳的影响，倘若时间回拨（当前服务器时间回到之前的某一时刻），那么 snowflake 有极大概率生成与之前同一时刻的重复 ID，这直接影响整个业务。</p><p>snowflake 受时间戳影响，使用上限不超过 70 年。</p><p>薄雾算法 Mist 由书籍《Python3 反爬虫原理与绕过实战》的作者韦世东综合 <a href="https://github.com/baidu/uid-generator">百度 UidGenerator在新窗口打开</a>、 <a href="https://tech.meituan.com/2017/04/21/mt-leaf.html">美团 Leaf在新窗口打开</a> 和 <a href="https://www.infoq.cn/article/wechat-serial-number-generator-architecture">微信序列号生成器 seqsvr在新窗口打开</a> 中介绍的技术点，同时考虑高性能分布式序列号生成器架构后设计的一款“递增态势、不依赖数据库、高性能且不受时间回拨影响”的全局唯一序列号生成算法。</p><p>薄雾算法不受时间戳影响，受到数值大小影响。薄雾算法高位数值上限计算方式为<code>int64(1&lt;&lt;47 - 1)</code>，上限数值<code>140737488355327</code> 百万亿级，假设每天消耗 10 亿，薄雾算法能使用 385+ 年。</p><h3 id="为什么薄雾算法不受时间回拨影响？"><a href="#为什么薄雾算法不受时间回拨影响？" class="headerlink" title="# 为什么薄雾算法不受时间回拨影响？"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95%E4%B8%8D%E5%8F%97%E6%97%B6%E9%97%B4%E5%9B%9E%E6%8B%A8%E5%BD%B1%E5%93%8D">#</a> 为什么薄雾算法不受时间回拨影响？</h3><p>snowflake 受时间回拨影响的根本原因是高位采用时间戳的二进制值，而薄雾算法的高位是按序递增的数值。结果值的大小由高位决定，遂薄雾算法不受时间回拨影响。</p><h3 id="为什么说薄雾算法的结果值不可预测？"><a href="#为什么说薄雾算法的结果值不可预测？" class="headerlink" title="# 为什么说薄雾算法的结果值不可预测？"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95%E7%9A%84%E7%BB%93%E6%9E%9C%E5%80%BC%E4%B8%8D%E5%8F%AF%E9%A2%84%E6%B5%8B">#</a> 为什么说薄雾算法的结果值不可预测？</h3><p>考虑到“不可预测”的要求，薄雾算法的中间位是 8 位随机值，且末 8 位是也是随机值，两组随机值大大增加了预测难度，因此称为结果值不可预测。</p><p>中间位和末位随机值的开闭区间都是 [0, 255]，理论上随机值可以出现 <code>256 * 256</code> 种组合。</p><h3 id="当程序重启，薄雾算法的值会重复吗？"><a href="#当程序重启，薄雾算法的值会重复吗？" class="headerlink" title="# 当程序重启，薄雾算法的值会重复吗？"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E5%BD%93%E7%A8%8B%E5%BA%8F%E9%87%8D%E5%90%AF-%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95%E7%9A%84%E5%80%BC%E4%BC%9A%E9%87%8D%E5%A4%8D%E5%90%97">#</a> 当程序重启，薄雾算法的值会重复吗？</h3><p>snowflake 受时间回拨影响，一旦时间回拨就有极大概率生成重复的 ID。薄雾算法中的高位是按序递增的数值，程序重启会造成按序递增数值回到初始值，但由于中间位和末尾随机值的影响，因此不是必定生成（有大概率生成）重复 ID，但递增态势必定受到影响。</p><h3 id="薄雾算法的值会重复，那我要它干嘛？"><a href="#薄雾算法的值会重复，那我要它干嘛？" class="headerlink" title="# 薄雾算法的值会重复，那我要它干嘛？"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95%E7%9A%84%E5%80%BC%E4%BC%9A%E9%87%8D%E5%A4%8D-%E9%82%A3%E6%88%91%E8%A6%81%E5%AE%83%E5%B9%B2%E5%98%9B">#</a> 薄雾算法的值会重复，那我要它干嘛？</h3><p>1、无论是什么样的全局唯一 ID 生成算法，都会有优点和缺点。在实际的应用当中，没有人会将全局唯一 ID 生成算法完全托付给程序，而是会用数据库存储关键值或者所有生成的值。全局唯一 ID 生成算法大多都采用分布式架构或者主备架构提供发号服务，这时候就不用担心它的重复问题；</p><p>2、生成性能比雪花算法高太多倍；</p><p>3、代码少且简单，在大型应用中，单功能越简单越好；</p><h3 id="薄雾算法的分布式架构，推荐-CP-还是-AP？"><a href="#薄雾算法的分布式架构，推荐-CP-还是-AP？" class="headerlink" title="# 薄雾算法的分布式架构，推荐 CP 还是 AP？"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84-%E6%8E%A8%E8%8D%90-cp-%E8%BF%98%E6%98%AF-ap">#</a> 薄雾算法的分布式架构，推荐 CP 还是 AP？</h3><p>CAP 是分布式架构中最重要的理论，C 指的是一致性、A 指的是可用性、P 指的是分区容错性。CAP 当中，C 和 A 是互相冲突的，且 P 一定存在，遂我们必须在 CP 和 AP 中选择。<strong>实际上这跟具体的业务需求有关</strong>，但是对于全局唯一 ID 发号服务来说，大多数时候可用性比一致性更重要，也就是选择 AP 会多过选择 CP。至于你怎么选，还是得结合具体的业务场景考虑。</p><h4 id="薄雾算法的性能测试"><a href="#薄雾算法的性能测试" class="headerlink" title="# 薄雾算法的性能测试"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95">#</a> 薄雾算法的性能测试</h4><p>采用 Golnag（1.14） 自带的 Benchmark 进行测试，测试机硬件环境如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">内存 16 GB 2133 MHz LPDDR3</span><br><span class="line">处理器 2.3 GHz 双核Intel Core i5</span><br><span class="line">操作系统 macOS Catalina</span><br><span class="line">机器 MacBook Pro (13-inch, 2017, Two Thunderbolt 3 ports)</span><br></pre></td></tr></table></figure><p>进行了多轮测试，随机取 3 轮测试结果。以此计算平均值，得 <code>单次执行时间 346 ns/op</code>。以下是随机 3 轮测试的结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">goos: darwin</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: mist</span><br><span class="line">BenchmarkMain-4          3507442               339 ns/op</span><br><span class="line">PASS</span><br><span class="line">ok      mist    1.345s</span><br><span class="line">goos: darwin</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: mist</span><br><span class="line">BenchmarkMain-4          3488708               338 ns/op</span><br><span class="line">PASS</span><br><span class="line">ok      mist    1.382s</span><br><span class="line">goos: darwin</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: mist</span><br><span class="line">BenchmarkMain-4          3434936               360 ns/op</span><br><span class="line">PASS</span><br><span class="line">ok      mist    1.394s</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="# 总结"></a><a href="https://wenotens.welink.huaweicloud.com/ks/note/view/e0135e50-16ed-11ee-805f-d3e05c744e88/5ab4a860-1722-11ee-beca-113105d0dc11/#%E6%80%BB%E7%BB%93">#</a> 总结</h2><p>以上基本列出了所有常用的分布式ID生成方式，其实大致分类的话可以分为两类：</p><ul><li><strong>一种是类DB型的</strong>，根据设置不同起始值和步长来实现趋势递增，需要考虑服务的容错性和可用性。</li><li><strong>另一种是类snowflake型</strong>，这种就是将64位划分为不同的段，每段代表不同的涵义，基本就是时间戳、机器ID和序列数。这种方案就是需要考虑时钟回拨的问题以及做一些 buffer的缓冲设计提高性能。</li></ul><p>而且可通过将三者（时间戳，机器ID，序列数）划分不同的位数来改变使用寿命和并发数。</p><p>例如对于并发数要求不高、期望长期使用的应用，可增加时间戳位数，减少序列数的位数. 例如配置成<code>&#123;&quot;workerBits&quot;:23,&quot;timeBits&quot;:31,&quot;seqBits&quot;:9&#125;</code>时, 可支持28个节点以整体并发量14400 UID&#x2F;s的速度持续运行68年。</p><p>对于节点重启频率频繁、期望长期使用的应用, 可增加工作机器位数和时间戳位数, 减少序列数位数. 例如配置成<code>&#123;&quot;workerBits&quot;:27,&quot;timeBits&quot;:30,&quot;seqBits&quot;:6&#125;</code>时, 可支持37个节点以整体并发量2400 UID&#x2F;s的速度持续运行34年。</p><p>著作权归@pdai所有 原文链接：<a href="https://pdai.tech/md/arch/arch-z-id.html">https://pdai.tech/md/arch/arch-z-id.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> learning </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
